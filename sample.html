<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2502.19402" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rpt_overview.png" alt="General Reasoning Requires Learning to Reason from the Get-go" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2502.19402" target="_blank">General Reasoning Requires Learning to Reason from the Get-go</a>
    </h3>
    <div class="paper-authors">Seungwook Han, Jyo Pari, Sam Gershman, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2025</span> <span class="paper-venue">arXiv</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2502.19402" class="paper-link">Paper PDF</a> <a href="data/han2025general.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Achieving true reasoning requires a new paradigm for pre-training
              based on rewards and iterative computation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2502.05970" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/blt-materials.png" alt="Known Unknowns: Out-of-Distribution Property Prediction in Materials and Molecules" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2502.05970" target="_blank">Known Unknowns: Out-of-Distribution Property Prediction in Materials and Molecules</a>
    </h3>
    <div class="paper-authors">Nofit Segal, Aviv Netanyahu, Kevin Greenman, Pulkit Agrawal â, Rafael GÃ³mez-Bombarelliâ</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">Workshop on AI for Accelerated Materials Design </span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2502.05970" class="paper-link">Paper PDF</a> <a href="https://github.com/learningmatter-mit/matex" class="paper-link">Code</a> <a href="data/segal2024known.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Extrapolating property prediction in materials science.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2502.10894" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ball_throw.gif" alt="Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2502.10894" target="_blank">Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation</a>
    </h3>
    <div class="paper-authors">Nolan Fey, Gabriel B. Margolis, Martin Peticco, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2025</span> <span class="paper-venue">Workshop on Robot Learning</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2502.10894" class="paper-link">Paper PDF</a> <a href="data/fey2025bridging.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Enhancing the sim-to-real transfer for extreme whole-body manipulation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2503.06358" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/pref.png" alt="Language Model Personalization via Reward Factorization" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2503.06358" target="_blank">Language Model Personalization via Reward Factorization</a>
    </h3>
    <div class="paper-authors">Idan Shenfeld, Felix Faltings, Pulkit Agrawal, Aldo Pacchiano, <a href="https://idanshenfeld.com" target="_blank">Idan Shenfeld*</a>, <a href="https://www.linkedin.com/in/felix-faltings-73b886127/" target="_blank">Felix Faltings*</a></div>
    <div class="paper-meta">
      <span class="paper-date"></span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2503.06358" class="paper-link">Paper PDF</a> <a href="data/shenfeld2025language.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Framework for personalizing large models assuming that human
              preferences lie on a low-dimensional manifold.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://residual-assembly.github.io/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ankile2024resip.gif" alt="From Imitation to Refinement â Residual RL for Precise Visual Assembly" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://residual-assembly.github.io/" target="_blank">From Imitation to Refinement â Residual RL for Precise Visual Assembly</a>
    </h3>
    <div class="paper-authors">Lars Ankile, Anthony Simeonov, Idan Shenfeld, Marcel Torne, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2025</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2407.16677" class="paper-link">Paper PDF</a> <a href="https://github.com/ankile/robust-rearrangement" class="paper-link">Code</a> <a href="data/ankile2024resip.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Refining behavior-cloned diffusion model policies using RL.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2502.10894" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ORSO_pipeline.png" alt="ORSO: Accelerating Reward Design via Online Reward
                Selection and Policy Optimization" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2502.10894" target="_blank">ORSO: Accelerating Reward Design via Online Reward
                Selection and Policy Optimization</a>
    </h3>
    <div class="paper-authors">Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2025</span> <span class="paper-venue">ORSO</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2410.13837" class="paper-link">Paper PDF</a> <a href="data/zhang2025orso.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Casting reward selection as a model selection leads to faster learning (upto 8x)
              and better performance (upto 2x) when training RL agents
              with provable regret guarantees.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2412.12953" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/mode_overview.png" alt="Efficient Diffusion Transformer Policies with
                Mixture of Expert Denoisers for Multitask Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2412.12953" target="_blank">Efficient Diffusion Transformer Policies with
                Mixture of Expert Denoisers for Multitask Learning</a>
    </h3>
    <div class="paper-authors">Moritz Reuss, Jyo Pari, Pulkit Agrawal, Rudolf Lioutikov, <a href="https://mbreuss.github.io/" target="_blank">Moritz Reuss*</a>, <a href="https://jyopari.github.io/" target="_blank">Jyo Pari*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2025</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2412.12953" class="paper-link">Paper PDF</a> <a href="data/reuss2025efficient.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">MoDE is a novel architecture that uses sparse experts and
              noise-conditioned routing.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://eyesighthand.github.io/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/eyesighthand.png" alt="EyeSight Hand: Design of a Fully-Actuated Dexterous
                Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://eyesighthand.github.io/" target="_blank">EyeSight Hand: Design of a Fully-Actuated Dexterous
                Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation</a>
    </h3>
    <div class="paper-authors">Branden Romero, Hao-Shu Fang, Pulkit Agrawal, Edward Adelson</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">IROS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2408.06265" class="paper-link">Paper PDF</a> <a href="data/romero2024eyesight.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A dexterous hand with proprioceptive actuation fully covered with tactile sensing.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2411.04987" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ftl-igm-robot.gif" alt="Few-Shot Task Learning through Inverse Generative Modeling" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2411.04987" target="_blank">Few-Shot Task Learning through Inverse Generative Modeling</a>
    </h3>
    <div class="paper-authors">Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2411.04987" class="paper-link">Paper PDF</a> <a href="https://github.com/avivne/ftl-igm/tree/main/code" class="paper-link">Code</a> <a href="data/netanyahu2024few-shot.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Few-shot continual learning via generative modeling.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2407.13755" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rle_conceptualization.png" alt="Random Latent Exploration for Deep Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2407.13755" target="_blank">Random Latent Exploration for Deep Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Srinath Mahankali, Zhang-Wei Hong, Ayush Sekhari, Alexander Rakhlin, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2407.13755" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/random-latent-exploration" class="paper-link">Code</a> <a href="data/mahankali2024random.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">State-of-the-art exploration by optimizing the agent to achieve randomly sampled
          latent goals.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2402.16828" target="_blank">
      <img src="https://minyoungg.github.io/LTE/assets/teaser.png" alt="Training Neural Networks From Scratch with Parallel Low-Rank Adapters" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2402.16828" target="_blank">Training Neural Networks From Scratch with Parallel Low-Rank Adapters</a>
    </h3>
    <div class="paper-authors">Minyoung Huh, Brian Cheung, Jeremy Bernstein, Phillip Isola, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">arXiv</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2402.16828" class="paper-link">Paper PDF</a> <a href="data/huh2024training.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A method for parallel training of large models on computers with
           limited memory.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2405.06639" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/vas_image.png" alt="Value Augmented Sampling for Language Model Alignment and Personalization" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2405.06639" target="_blank">Value Augmented Sampling for Language Model Alignment and Personalization</a>
    </h3>
    <div class="paper-authors">Seungwook Han, Idan Shenfeld, Akash Srivastava, Yoon Kim, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">Workshop on Reliable and Responsible Foundation Models </span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2405.06639" class="paper-link">Paper PDF</a> <a href="data/han2024value.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Algorithm for inference-time augmentation of Large Language Models.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2309.14321" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/halp.gif" alt="Lifelong Robot Learning with Human Assisted Language Planners" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2309.14321" target="_blank">Lifelong Robot Learning with Human Assisted Language Planners</a>
    </h3>
    <div class="paper-authors">Meenal Parakh, Alisha Fong, Anthony Simeonov, Abhishek Gupta, Tao Chen, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2309.14321" class="paper-link">Paper PDF</a> <a href="data/parakh2024lifelong.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">An LLM-based task planner that can learn new skills
              opens doors for continual learning.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://arxiv.org/abs/2405.01402" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/learning_force_control.gif" alt="Learning Force Control for Legged Manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://arxiv.org/abs/2405.01402" target="_blank">Learning Force Control for Legged Manipulation</a>
    </h3>
    <div class="paper-authors">Tifanny Portela, Gabriel B. Margolis, Yandong Ji, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="http://arxiv.org/abs/2405.01402.pdf" class="paper-link">Paper PDF</a> <a href="data/portela2024learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning to control the force applied by a legged robot's arm for compliant and forceful manipulation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://arxiv.org/abs/2405.01402" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/avatar_curisoity_redteam.png" alt="Curiosity-driven Red-teaming for Large Language Models" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://arxiv.org/abs/2405.01402" target="_blank">Curiosity-driven Red-teaming for Large Language Models</a>
    </h3>
    <div class="paper-authors">Zhang-Wei Hong, Idan Shenfeld, Tsun-Hsuan Wang, Yung-Sung Chuang, Aldo Pareja, James R. Glass, Akash Srivastava, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2402.19464.pdf" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/curiosity_redteam" class="paper-link">Code</a> <a href="bibtex/hong2024curiosity.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract"></p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://ieeexplore.ieee.org/abstract/document/10609983" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/eipo_spin.gif" alt="Maximizing Quadruped Velocity by Minimizing Energy" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://ieeexplore.ieee.org/abstract/document/10609983" target="_blank">Maximizing Quadruped Velocity by Minimizing Energy</a>
    </h3>
    <div class="paper-authors">Srinath Mahankali, Chi-Chang Lee, Gabriel B. Margolis, Zhang-Wei Hong, Pulkit Agrawal, <a href="https://srinathm1359.github.io/" target="_blank">Srinath Mahankali*</a>, <a href="https://dblp.org/pid/258/6861.html" target="_blank">Chi-Chang Lee*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://ieeexplore.ieee.org/abstract/document/10609983" class="paper-link">Paper PDF</a> <a href="data/mahankali2024maximizing.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Principled energy minimization increases robot's agility.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://imitation-juicer.github.io/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/juicer.gif" alt="JUICER: Data-Efficient Imitation Learning for Robotic Assembly" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://imitation-juicer.github.io/" target="_blank">JUICER: Data-Efficient Imitation Learning for Robotic Assembly</a>
    </h3>
    <div class="paper-authors">Lars Ankile, Anthony Simeonov, Idan Shenfeld, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">JUICER</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2404.03729" class="paper-link">Paper PDF</a> <a href="https://github.com/ankile/imitation-juicer" class="paper-link">Code</a> <a href="data/ankile2024juicer.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning complex assembly skills from few human demonstrations.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://rank2reward.github.io/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rank2reward.png" alt="Rank2Reward: Learning Shaped Reward Functions from Passive Video" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://rank2reward.github.io/" target="_blank">Rank2Reward: Learning Shaped Reward Functions from Passive Video</a>
    </h3>
    <div class="paper-authors">Daniel Yang, Davin Tjia, Jacob Berg, Dima Damen, Pulkit Agrawal, Abhishek Gupta</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2404.14735" class="paper-link">Paper PDF</a> <a href="https://github.com/ankile/imitation-juicer" class="paper-link">Code</a> <a href="data/yang2024rank.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning reward functions from videos of human demonstrations.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2408.04142" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/everyday_finger.png" alt="Everyday finger: a robotic finger that meets the needs of everyday interactive manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2408.04142" target="_blank">Everyday finger: a robotic finger that meets the needs of everyday interactive manipulation</a>
    </h3>
    <div class="paper-authors">RubÃ©n Castro Ornelas, TomÃ¡s CantÃº, Isabel Sperandio, Alexander H. Slocum, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2024</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2408.04142" class="paper-link">Paper PDF</a> <a href="data/ornelas2024everyday.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Robotic finger designed to perform every day tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://browse.arxiv.org/pdf/2309.08587.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/hip.png" alt="Compositional Foundation Models for Hierarchical Planning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://browse.arxiv.org/pdf/2309.08587.pdf" target="_blank">Compositional Foundation Models for Hierarchical Planning</a>
    </h3>
    <div class="paper-authors">Anurag Ajay, Seungwook Han, Yilun Du, Shuang Li, Abhi Gupta, Tommi Jaakkola, Josh Tenenbaum, Leslie Kaelbling, Akash Srivastava, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://browse.arxiv.org/pdf/2309.08587.pdf" class="paper-link">Paper PDF</a> <a href="data/ajay2023compositional.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Composing existing foundation models operating on different modalities to solve long-horizon tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://browse.arxiv.org/pdf/2307.11049.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/huge2023.png" alt="Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-Loop Feedback" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://browse.arxiv.org/pdf/2307.11049.pdf" target="_blank">Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-Loop Feedback</a>
    </h3>
    <div class="paper-authors">Marcel Torne, Max Balsells, Zihan Wang, Samedh Desai, Tao Chen, Pulkit Agrawal, Abhishek Gupta</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://browse.arxiv.org/pdf/2307.11049.pdf" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/human-guided-exploration" class="paper-link">Code</a> <a href="data/torne2023breadcrumbs.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Method for guiding goal-directed exploration with asynchronous human feedback.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="<https://arxiv.org/pdf/2310.04413.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/dw_teaser.gif" alt="Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="<https://arxiv.org/pdf/2310.04413.pdf" target="_blank">Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets</a>
    </h3>
    <div class="paper-authors">Zhang-Wei Hong, Aviral Kumar, Sathwik Karnik, Abhishek Bhandwaldar, Akash Srivastava, Joni Pajarinen, Romain Laroche, Abhishek Gupta, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2310.04413.pdf" class="paper-link">Paper PDF</a> <a href="data/hong2023beyond.bib" class="paper-link">BibTeX</a> <a href="https://github.com/Improbable-AI/dw-offline-rl" class="paper-link">Code</a></div>
    <p class="paper-abstract">Optimizing the sampling distribution enables offline RL to learn a good policy in skewed datasets primarily
                  composed of sub-optimal trajectories.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2307.04751" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rpdiff.gif" alt="Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2307.04751" target="_blank">Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement</a>
    </h3>
    <div class="paper-authors">Anthony Simeonov, Ankit Goyal, Lucas Manuelli, Lin Yen-Chen, Alina Sarmiento, Alberto Rodriguez, Pulkit Agrawal, Dieter Fox</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2307.04751" class="paper-link">Paper PDF</a> <a href="https://github.com/anthonysimeonov/rpdiff" class="paper-link">Code</a> <a href="data/simeonov2023shelving.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Relational rearrangement with multi-modal placing and generalization over scene layouts via diffusion and local scene conditioning.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2311.01405" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/asmp_miniclip_small.gif" alt="Learning to See Physical Properties with Active Sensing Motor Policies" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2311.01405" target="_blank">Learning to See Physical Properties with Active Sensing Motor Policies</a>
    </h3>
    <div class="paper-authors">Gabriel B. Margolis, Xiang Fu, Yandong Ji, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">Conference on Robot Learning (CoRL)</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2311.01405" class="paper-link">Paper PDF</a> <a href="" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learn to perceive physical properties of terrains in front of the robot (i.e., a digital twin).</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://yanweiw.github.io/noise2ptz/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/noise2ptz.png" alt="Visual Pre-training for Navigation: What Can We Learn from Noise?" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://yanweiw.github.io/noise2ptz/" target="_blank">Visual Pre-training for Navigation: What Can We Learn from Noise?</a>
    </h3>
    <div class="paper-authors">Yanwei Wang, Ching-Yun Ko, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">IROS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2207.00052" class="paper-link">Paper PDF</a> <a href="https://github.com/yanweiw/noise2ptz" class="paper-link">Code</a> <a href="data/wang2023visual.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning to navigate by moving the camera across random images.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/pdf?id=z3D__-nc9y" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/gear2023.png" alt="Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/pdf?id=z3D__-nc9y" target="_blank">Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback</a>
    </h3>
    <div class="paper-authors">Max Balsells, Marcel Torne, Zihan Wang, Samedh Desai, Pulkit Agrawal, Abhishek Gupta</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/pdf?id=z3D__-nc9y" class="paper-link">Paper PDF</a> <a href="data/pamies2023autonomous.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Leveraging crowdsourced non-expert human feedback to guide exploration in robot policy learning.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2307.03186" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/tgrl.png" alt="TGRL: An Algorithm for Teacher Guided Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2307.03186" target="_blank">TGRL: An Algorithm for Teacher Guided Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Idan Shenfeld, Zhang-Wei Hong, Aviv Tamar, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">TGRL</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2307.03186" class="paper-link">Paper PDF</a> <a href="https://github.com/idanshen/cleanrl/blob/master/cleanrl/tgrl_continuous_action.py" class="paper-link">Code</a> <a href="data/shenfeld2023tgrl.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">An algorithm for automatically balancing learning from teacher's
              guidance and task reward.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://minyoungg.github.io/vqtorch/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/vq2023.png" alt="Straightening Out the Straight-Through Estimator: Overcoming
                Optimization Challenges in Vector Quantized Networks" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://minyoungg.github.io/vqtorch/" target="_blank">Straightening Out the Straight-Through Estimator: Overcoming
                Optimization Challenges in Vector Quantized Networks</a>
    </h3>
    <div class="paper-authors">Minyoung Huh, Brian Cheung, Pulkit Agrawal, Phillip Isola
             
 International</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">Conference on Machine Learning ( ICML ) </span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2305.08842" class="paper-link">Paper PDF</a> <a href="https://github.com/minyoungg/vqtorch" class="paper-link">Code</a> <a href="data/huh2023straightening.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A set of suggestions that simplifies training of vector quantization layers.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2307.12983" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/pql.png" alt="Parallel Q-Learning: Scaling Off-policy Reinforcement Learning under
                Massively Parallel Simulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2307.12983" target="_blank">Parallel Q-Learning: Scaling Off-policy Reinforcement Learning under
                Massively Parallel Simulation</a>
    </h3>
    <div class="paper-authors">Zechu Li, Tao Chen, Zhang-Wei Hong, Anurag Ajay, Pulkit Agrawal, <a href="https://supersglzc.github.io/" target="_blank">Zechu Li*</a>, <a href="https://taochenshh.github.io/" target="_blank">Tao Chen*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2307.12983" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/pql" class="paper-link">Code</a> <a href="data/li2023parallel.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Scaling Q-learning algorithms to 10K+ workers.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2307.06333.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/counterfactual.png" alt="Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2307.06333.pdf" target="_blank">Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation</a>
    </h3>
    <div class="paper-authors">Andi Peng, Aviv Netanyahu, Mark Ho, Tianmin Shu, Andreea Bobu, Julie Shah, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2307.06333.pdf" class="paper-link">Paper PDF</a> <a href="data/peng2023diagnosis.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A step towards using counterfactuals for improving policy adaptation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://browse.arxiv.org/pdf/2302.13934.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/distshift.png" alt="Statistical Learning under Heterogenous Distribution Shift" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://browse.arxiv.org/pdf/2302.13934.pdf" target="_blank">Statistical Learning under Heterogenous Distribution Shift</a>
    </h3>
    <div class="paper-authors">Max Simchowitz, Anurag Ajay, Pulkit Agrawal, Akshay Krishnamurthy</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://browse.arxiv.org/pdf/2302.13934.pdf" class="paper-link">Paper PDF</a> <a href="data/simchowitz2023statistical.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">In-distribution error for certain features
              predicts their out-of-distribution sensitivity.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://gmargo11.github.io/dribblebot" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/dribblebot_field.png" alt="DribbleBot: Dynamic Legged Manipulation in the Wild" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://gmargo11.github.io/dribblebot" target="_blank">DribbleBot: Dynamic Legged Manipulation in the Wild</a>
    </h3>
    <div class="paper-authors">Yandong Ji, Gabriel B. Margolis, Pulkit Agrawal    
 International, <a href="https://yandongji.github.io/" target="_blank">Yandong Ji*</a>, <a href="https://gmargo11.github.io/" target="_blank">Gabriel B. Margolis*</a>, <a href="https://techcrunch.com/2023/04/03/this-robot-dog-can-play-soccer-and-grass-mud-and-sand/" target="_blank">TechCrunch</a>, <a href="https://spectrum.ieee.org/quadrupedal-robot" target="_blank">IEEE Spectrum</a>, <a href="https://archive.tveyes.com/7313/meltwater/3fa732c9-740b-4602-a9e6-f9b44988c02b/WBTS_04-04-2023_04.55.00.mp4" target="_blank">NBC Boston</a>, <a href="https://www.yahoo.com/lifestyle/robots-getting-good-dribbling-soccer-163646616.html" target="_blank">Yahoo!News</a>, <a href="https://news.mit.edu/2023/legged-robotic-system-playing-soccer-various-terrains-0403" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">Conference on Robotics and Automation ( ICRA )</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2304.01159" class="paper-link">Paper PDF</a> <a href="data/ji2023dribblebot.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Dynamic legged object manipulation on diverse terrains with onboard compute and sensing.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2211.15657.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/decisiondiff.gif" alt="Is Conditional Generative Modeling all you need for Decision Making?" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2211.15657.pdf" target="_blank">Is Conditional Generative Modeling all you need for Decision Making?</a>
    </h3>
    <div class="paper-authors">Anurag Ajay, Yilun Du, Abhi Gupta, Josh Tenenbaum, Tommi Jaakkola, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2211.15657.pdf" class="paper-link">Paper PDF</a> <a href="data/ajay2023is.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Return conditioned generative models offer a powerful alternative to temporal-difference learning
                for offline decision making and reasoning with constraints.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2304.14329" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/transduction.png" alt="Learning to Extrapolate: A Transductive Approach" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2304.14329" target="_blank">Learning to Extrapolate: A Transductive Approach</a>
    </h3>
    <div class="paper-authors">Aviv Netanyahu, Abhishek Gupta, Max Simchowitz, Kaiqing Zhang, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2304.14329" class="paper-link">Paper PDF</a> <a href="data/netanyahu2023learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Transductive reparameterization converts out-of-support generalization problem into out-of-combination generalization which
                is possible under low-rank style conditions.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/forum?id=OhUAblg27z" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/avatar_harness.png" alt="Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/forum?id=OhUAblg27z" target="_blank">Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting</a>
    </h3>
    <div class="paper-authors">Zhang-Wei Hong, Pulkit Agrawal, Remi Tachet des Combes, Romain Laroche</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=OhUAblg27z" class="paper-link">Paper PDF</a> <a href="data/hong2023harness.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Return reweighted sampling of trajectories enables offline RL algorithms to work with skewed datasets.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://minyoungg.github.io/overparam/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/low-rank-bias.png" alt="The Low-Rank Simplicity Bias in Deep Networks" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://minyoungg.github.io/overparam/" target="_blank">The Low-Rank Simplicity Bias in Deep Networks</a>
    </h3>
    <div class="paper-authors">Minyoung Huh, Hossein Mobahi, Richard Zhang, Brian Cheung, Pulkit Agrawal, Phillip Isola
              
 Transactions of Machine Learning Research, 2023</div>
    <div class="paper-meta">
      <span class="paper-date">2023</span> <span class="paper-venue">TMLR</span>
    </div>
    <div class="paper-links"><a href="https://minyoungg.github.io/overparam/resources/overparam-v3.pdf" class="paper-link">Paper PDF</a> <a href="data/huh2023low.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Deeper Networks find simpler solutions! Also learn why ResNets overcome
             the challenges associated with very deep networks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://sites.google.com/view/neurips22-eipo/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/eipo.png" alt="Redeeming Intrinsic Rewards via Constrained Optimization" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://sites.google.com/view/neurips22-eipo/" target="_blank">Redeeming Intrinsic Rewards via Constrained Optimization</a>
    </h3>
    <div class="paper-authors">Eric Chen, Zhang-Wei Hong, Joni Pajarinen, Pulkit Agrawal, <a href="https://news.mit.edu/2022/ensuring-ai-works-with-right-dose-curiosity-1110" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2211.07627" class="paper-link">Paper PDF</a> <a href="data/chen2022redeeming.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Method that automatically balances exploration bonus or curiosity against task rewards leading to consistent performance improvement.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2211.09786" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rndf_bowl_bottle.gif" alt="SE(3)-Equivariant Relational Rearrangement with Neural Descriptor Fields" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2211.09786" target="_blank">SE(3)-Equivariant Relational Rearrangement with Neural Descriptor Fields</a>
    </h3>
    <div class="paper-authors">Anthony Simeonov, Yilun Du, Lin Yen-Chen, Alberto Rodriguez, Leslie P. Kaelbling, Tomás Lozano-Peréz, Pulkit Agrawal, <a href="https://anthonysimeonov.github.io/" target="_blank">Anthony Simeonov*</a>, <a href="https://yilundu.github.io/" target="_blank">Yilun Du*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2211.09786" class="paper-link">Paper PDF</a> <a href="https://github.com/anthonysimeonov/relational_ndf" class="paper-link">Code</a> <a href="data/simeonov2022se.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning relational tasks with a few demonstrations in a way that generalizes to new configurations of objects.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://sites.google.com/view/gait-conditioned-rl/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/walk-these-ways.png" alt="Walk These Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://sites.google.com/view/gait-conditioned-rl/" target="_blank">Walk These Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior</a>
    </h3>
    <div class="paper-authors">Gabriel B. Margolis, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/pdf?id=52c5e73SlS2" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/walk-these-ways" class="paper-link">Code</a> <a href="data/margolis2022walk.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">One learned policy embodies many dynamic behaviors useful for different tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/pdf?id=2ovFjGGDFjc" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/diametr_web.png" alt="Distributionally Adaptive Meta Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/pdf?id=2ovFjGGDFjc" target="_blank">Distributionally Adaptive Meta Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Anurag Ajay, Abhishek Gupta, Dibya Ghosh, Sergey Levine, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=2ovFjGGDFjc" class="paper-link">Paper PDF</a> <a href="data/ajay2022distributionally.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Being adaptive instead of being robust results in faster adaption to
                out-of-distribution tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://tactilesim.csail.mit.edu/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/touch_sim_2022.jpeg" alt="Efficient Tactile Simulation with Differentiability for Robotic Manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://tactilesim.csail.mit.edu/" target="_blank">Efficient Tactile Simulation with Differentiability for Robotic Manipulation</a>
    </h3>
    <div class="paper-authors">Jie Xu, Sangwoon Kim, Tao Chen, Alberto Rodriguez, Pulkit Agrawal, Wojciech Matusik, Shinjiro Sueda</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://people.csail.mit.edu/jiex/papers/TactileSim/paper.pdf" class="paper-link">Paper PDF</a> <a href="" class="paper-link">Code</a> <a href="data/xu2022efficient.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Tactile Simulator for complex shapes training on which transfers to real-world.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://agility.csail.mit.edu" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/cheetah-spin-2022.png" alt="Rapid Locomotion via Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://agility.csail.mit.edu" target="_blank">Rapid Locomotion via Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Gabriel Margolis, Ge Yang, Kartik Paigwar, Tao Chen, Pulkit Agrawal  
 
 RSS, 2022, <a href="https://www.wired.com/story/this-cheetah-robot-taught-itself-how-to-sprint-in-a-weird-way/" target="_blank">Wired</a>, <a href="https://www.popsci.com/technology/machine-learning-robot-runs-its-fastest/" target="_blank">Popular Science</a>, <a href="https://techcrunch.com/2022/03/17/to-servi-man/" target="_blank">TechCrunch</a>, <a href="https://www.bbc.com/news/av/technology-60795221" target="_blank">BBC</a>, <a href="https://news.mit.edu/2022/3-questions-how-mit-mini-cheetah-learns-run-fast-0317" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">RSS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2205.02824.pdf" class="paper-link">Paper PDF</a> <a href="https://agility.csail.mit.edu" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">High-speed running and spinning on diverse terrains with a RL based controller.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2203.07359.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/stubborn_cropped_iros22.gif" alt="Stubborn: A Strong Baseline for Indoor Object Navigation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2203.07359.pdf" target="_blank">Stubborn: A Strong Baseline for Indoor Object Navigation</a>
    </h3>
    <div class="paper-authors">Haokuan Luo, Albert Yue, Zhang-Wei Hong, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">IROS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2203.07359.pdf" class="paper-link">Paper PDF</a> <a href="https://github.com/Improbable-AI/Stubborn" class="paper-link">Code</a> <a href="data/luo2022stubborn.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">State-of-the-art Performance on Habitat Navigation Challenge without any machine learning
            for navigation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2112.05124" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/mug_cut.gif" alt="Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2112.05124" target="_blank">Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation</a>
    </h3>
    <div class="paper-authors">Anthony Simeonov, Yilun Du, Andrea Tagliasacchi, Joshua B. Tenenbaum, Alberto Rodriguez, Pulkit Agrawal, Vincent Sitzmann</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2112.05124" class="paper-link">Paper PDF</a> <a href="https://yilundu.github.io/ndf/" class="paper-link">Code</a> <a href="data/simeonov2021neural.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">An SE(3) Equivariant method for specifiying and finding correspondences which enables data efficient object manipulation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2204.07149.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/robohand_teaser.png" alt="An Integrated Design Pipeline for Tactile Sensing Robotic Manipulators" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2204.07149.pdf" target="_blank">An Integrated Design Pipeline for Tactile Sensing Robotic Manipulators</a>
    </h3>
    <div class="paper-authors">Lara Zlokapa, Yiyue Luo, Jie Xu, Michael Foshey, Kui Wu, Pulkit Agrawal, Wojciech Matusik</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2204.07149.pdf" class="paper-link">Paper PDF</a> <a href="data/zlokapa2022integrated.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A method for users to easily design a variety of robotic manipulators with integrated tactile sensors.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://richardrl.github.io/stable-reorientation/resources/ICRA_2022__Stable_Object_Reorientation_using_Contact_Plane_Registration.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/icra2022_stacking.png" alt="Stable Object Reorientation using Contact Plane Registration" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://richardrl.github.io/stable-reorientation/resources/ICRA_2022__Stable_Object_Reorientation_using_Contact_Plane_Registration.pdf" target="_blank">Stable Object Reorientation using Contact Plane Registration</a>
    </h3>
    <div class="paper-authors">Richard Li, Carlos Esteves, Ameesh Makadia, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2208.08962" class="paper-link">Paper PDF</a> <a href="data/li2022stable.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Predicting contact points with a CVAE and plane segmentation improves object generalization and handles multimodality.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://proceedings.mlr.press/v162/netanyahu22a.html" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/GEM.jpg" alt="Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://proceedings.mlr.press/v162/netanyahu22a.html" target="_blank">Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning</a>
    </h3>
    <div class="paper-authors">Aviv Netanyahu, Tianmin Shu, Joshua B. Tenenbaum, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="<https://proceedings.mlr.press/v162/netanyahu22a.html>" class="paper-link">Paper PDF</a> <a href="data/netanyahu2022discovering.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Graph-based one-shot reward learning via active learning for object rearrangement tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2207.02200.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/icml_2022_pic.png" alt="Offline RL Policies Should be Trained to be Adaptive" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2207.02200.pdf" target="_blank">Offline RL Policies Should be Trained to be Adaptive</a>
    </h3>
    <div class="paper-authors">Dibya Ghosh, Anurag Ajay, Pulkit Agrawal, Sergey Levine</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2207.02200.pdf" class="paper-link">Paper PDF</a> <a href="data/ghosh2022offline.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Online adaptation of offline RL policies using evaluation data improves
          performance.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/forum?id=OXRZeMmOI7a" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ter.png" alt="Topological Experience Replay" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/forum?id=OXRZeMmOI7a" target="_blank">Topological Experience Replay</a>
    </h3>
    <div class="paper-authors">Zhang-Wei Hong, Tao Chen, Yen-Chen Lin, Joni Pajarinen, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=OXRZeMmOI7a" class="paper-link">Paper PDF</a> <a href="data/hong2022topological.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Sampling data from the replay buffer informed by topological structure
          of the state space improves performance.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/forum?id=LedObtLmCjS" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/bvn.png" alt="Bilinear Value Networks for Multi-goal Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/forum?id=LedObtLmCjS" target="_blank">Bilinear Value Networks for Multi-goal Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Zhang-Wei Hong, Ge Yang, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=LedObtLmCjS" class="paper-link">Paper PDF</a> <a href="data/hong2022bilinear.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Bilinear decomposition of the Q-value function improves generalization and
            data efficiency.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2111.00899.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/construction.png" alt="Equivariant Contrastive Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2111.00899.pdf" target="_blank">Equivariant Contrastive Learning</a>
    </h3>
    <div class="paper-authors">Rumen Dangovski, Li Jing, Charlotte Loh, Seungwook Han, Akash Srivastava, Brian Cheung, Pulkit Agrawal, Marin Soljacic</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2111.00899.pdf" class="paper-link">Paper PDF</a> <a href="data/dangovski2021equivariant.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Study revealing complementarity of invariance and equivariance in contrastive learning.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://people.csail.mit.edu/pulkitag/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rff.png" alt="Overcoming The Spectral Bias of Neural Value Approximation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://people.csail.mit.edu/pulkitag/" target="_blank">Overcoming The Spectral Bias of Neural Value Approximation</a>
    </h3>
    <div class="paper-authors">Ge Yang, Anurag Ajay, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2022</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2206.04672" class="paper-link">Paper PDF</a> <a href="data/yang2022overcoming.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Fourier features improve value estimation and consequently data efficiency.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://taochenshh.github.io/projects/in-hand-reorientation" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/hand_reori.gif" alt="A System for General In-Hand Object Re-Orientation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://taochenshh.github.io/projects/in-hand-reorientation" target="_blank">A System for General In-Hand Object Re-Orientation</a>
    </h3>
    <div class="paper-authors">Tao Chen, Jie Xu, Pulkit Agrawal, <a href="https://news.mit.edu/2021/dexterous-robotic-hands-manipulate-thousands-objects-1112" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">MIT</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=7uSBJDoP7tY" class="paper-link">Paper PDF</a> <a href="data/chen2021system.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A framework for general in-hand object reorientation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/pdf?id=R4E8wTUtxdl" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/cheetah-jump.gif" alt="Learning to Jump from Pixels" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/pdf?id=R4E8wTUtxdl" target="_blank">Learning to Jump from Pixels</a>
    </h3>
    <div class="paper-authors">Gabriel Margolis, Tao Chen, Kartik Paigwar, Xiang Fu, Donghyun Kim, Sangbae Kim, Pulkit Agrawal, <a href="https://news.mit.edu/2021/one-giant-leap-mini-cheetah-1020" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">MIT</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/pdf?id=R4E8wTUtxdl" class="paper-link">Paper PDF</a> <a href="data/margolis2021jumping.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A hierarchical control framework for dynamic vision-aware locomotion.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://3d-representation-learning.github.io/nerf-dy/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/nerf3d.png" alt="3D Neural Scene Representations for Visuomotor Control" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://3d-representation-learning.github.io/nerf-dy/" target="_blank">3D Neural Scene Representations for Visuomotor Control</a>
    </h3>
    <div class="paper-authors">Yunzhu Li, Shuang Li, Vincent Sitzmann, Pulkit Agrawal, Antonio Torralba</div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">CoRL</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2107.04004" class="paper-link">Paper PDF</a> <a href="data/li20213d.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Extreme viewpoint generalization via 3D representations based on Neural Radiance Fields.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/2107.07501.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/handdesign2021.jpeg" alt="An End-to-End Differentiable Framework for Contact-Aware Robot Design" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/2107.07501.pdf" target="_blank">An End-to-End Differentiable Framework for Contact-Aware Robot Design</a>
    </h3>
    <div class="paper-authors">Jie Xu, Tao Chen, Lara Zlokapa, Michael Foshey, Wojciech Matusik, Shinjiro Sueda, Pulkit Agrawal  
 
 RSS, 2021, <a href="https://news.mit.edu/2021/contact-aware-robot-design-0719" target="_blank">MIT News</a></div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">RSS</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/abs/2107.07501.pdf" class="paper-link">Paper PDF</a> <a href="data/xu2021end.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Computational method for design task-specific robotic hands.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2106.15612.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/tia2021.gif" alt="Learning Task Informed Abstractions" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2106.15612.pdf" target="_blank">Learning Task Informed Abstractions</a>
    </h3>
    <div class="paper-authors">Xiang Fu, Ge Yang, Pulkit Agrawal, Tommi Jaakkola</div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2106.15612.pdf" class="paper-link">Paper PDF</a> <a href="data/fu2021learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A MDP formulation that dissociates task relevant and irrelevant information.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/2104.00631.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/hamr-rml.png" alt="Residual Model Learning for Microrobot Control" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/2104.00631.pdf" target="_blank">Residual Model Learning for Microrobot Control</a>
    </h3>
    <div class="paper-authors">Joshua Gruenstein, Tao Chen, Neel Doshi, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2104.00631.pdf" class="paper-link">Paper PDF</a> <a href="data/gruenstein2021residual.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Data efficient learning method for controlling microrobots.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://sites.google.com/view/opal-iclr" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/opal.gif" alt="OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://sites.google.com/view/opal-iclr" target="_blank">OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Anurag Ajay, Aviral Kumar, Pulkit Agrawal, Sergey Levine, Ofir Nachum</div>
    <div class="paper-meta">
      <span class="paper-date">2021</span> <span class="paper-venue">OPAL</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2010.13611.pdf" class="paper-link">Paper PDF</a> <a href="data/ajay2021opal.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Learning action primitives for data efficient online and offline RL.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://anthonysimeonov.github.io/rpo-planning-framework/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/multistep_intro.png" alt="A Long Horizon Planning Framework for Manipulating Rigid Pointcloud Objects" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://anthonysimeonov.github.io/rpo-planning-framework/" target="_blank">A Long Horizon Planning Framework for Manipulating Rigid Pointcloud Objects</a>
    </h3>
    <div class="paper-authors">Anthony Simeonov, Yilun Du, Beomjoon Kim, Francois Hogan, Joshua Tenenbaum, Pulkit Agrawal, Alberto Rodriguez</div>
    <div class="paper-meta">
      <span class="paper-date">2020</span> <span class="paper-venue">TAMP</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/2011.08177.pdf" class="paper-link">Paper PDF</a> <a href="data/simeonov2020learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A framework that achieves the best of TAMP and robot-learning
                for manipulating rigid objects.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://richardrl.github.io/relational-rl/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/block-stacking-2019.gif" alt="Towards Practical Multi-object Manipulation using
Relational Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://richardrl.github.io/relational-rl/" target="_blank">Towards Practical Multi-object Manipulation using
Relational Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Richard Li, Allan Jabri, Trevor Darrell, Pulkit Agrawal</div>
    <div class="paper-meta">
      <span class="paper-date">2020</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/1912.11032.pdf" class="paper-link">Paper PDF</a> <a href="https://github.com/richardrl/rlkit-relational" class="paper-link">Code</a> <a href="data/li2019towards.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Combining graph neural networks with curriculum learning for solve
            long horizon multi-object manipulation tasks.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/1902.05522" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/superposition_nutshell.png" alt="Superposition of Many Models into One" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/1902.05522" target="_blank">Superposition of Many Models into One</a>
    </h3>
    <div class="paper-authors">Brian Cheung, Alex Terekhov, Yubei Chen, Pulkit Agrawal, Bruno Olshausen</div>
    <div class="paper-meta">
      <span class="paper-date">2019</span> <span class="paper-venue">IPS</span>
    </div>
    <div class="paper-links"><a href="https://github.com/briancheung/superposition" class="paper-link">Code</a> <a href="data/cheung2019superposition.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A method for storing multiple neural network models for different
                tasks into a single neural network.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://ajmc.s3.amazonaws.com/_media/_pdf/AJMC_07_2019_Xiong%20final.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/emt_2019.png" alt="Real-time Video Detection of Falls in Dementia Care
                  Facility and Reduced Emergency Care" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://ajmc.s3.amazonaws.com/_media/_pdf/AJMC_07_2019_Xiong%20final.pdf" target="_blank">Real-time Video Detection of Falls in Dementia Care
                  Facility and Reduced Emergency Care</a>
    </h3>
    <div class="paper-authors">Glen L Xiong, Eleonore Bayen, Shirley Nickels, Raghav Subramaniam, Pulkit Agrawal, Julien Jacquemot, Alexandre M Bayen, Bruce Miller, George Netscher
               
 American Journal of Managed Care, 2019, <a href="https://www.safely-you.com/" target="_blank">SafelyYou</a></div>
    <div class="paper-meta">
      <span class="paper-date">2019</span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="https://ajmc.s3.amazonaws.com/_media/_pdf/AJMC_07_2019_Xiong%20final.pdf" class="paper-link">Paper PDF</a> <a href="data/xiong2019real.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Computer Vision based Fall Detection system reduces number of
              falls and emergency room visits in people with Dementia.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://openreview.net/pdf?id=BkisuzWRW" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/iclr18_1.gif " alt="Zero Shot Visual Imitation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://openreview.net/pdf?id=BkisuzWRW" target="_blank">Zero Shot Visual Imitation</a>
    </h3>
    <div class="paper-authors">Deepak Pathak, Parsa Mahmoudieh, Michael Luo, Pulkit Agrawal, Evan Shelhamer, Alexei A. Efros, Trevor Darrell, <a href="https://people.eecs.berkeley.edu/~pathak/" target="_blank">Deepak Pathak*</a>, <a href="https://people.eecs.berkeley.edu/~parsa.m/" target="_blank">Parsa Mahmoudieh*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2018</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://openreview.net/forum?id=BkisuzWRW" class="paper-link">Paper PDF</a> <a href="https://github.com/pathak22/zeroshot-imitation" class="paper-link">Code</a> <a href="data/pathak2018zero.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Self-supervised learning of skills helps an agent imitate
              the task presented as a sequence of images. Forward consistency loss
              overcomes key challenges of inverse and forward models.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://rach0012.github.io/humanRL_website/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/icml18.png" alt="Investigating Human Priors for Playing Video Games" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://rach0012.github.io/humanRL_website/" target="_blank">Investigating Human Priors for Playing Video Games</a>
    </h3>
    <div class="paper-authors">Rachit Dubey, Pulkit Agrawal, Deepak Pathak, Alexei A. Efros, Tom Griffiths, <a href="https://youtu.be/Ol0-c9OE3VQ" target="_blank">youtube cover</a>, <a href="https://rach0012.github.io/humanRL_website/#media" target="_blank">media</a></div>
    <div class="paper-meta">
      <span class="paper-date">2018</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/1802.10217.pdf" class="paper-link">Paper PDF</a> <a href="data/dubey2018investigating.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">An empirical study of various kinds of prior information used
                by humans to solve video games. Such priors make them significantly
              more sample efficient as compared to Deep Reinforcement Learning algorithms.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://pathak22.github.io/seg-by-interaction/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/instance_segmentation.png" alt="Learning Instance Segmentation by Interaction" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://pathak22.github.io/seg-by-interaction/" target="_blank">Learning Instance Segmentation by Interaction</a>
    </h3>
    <div class="paper-authors">Deepak Pathak, Yide Shentu, Dian Chen, Pulkit Agrawal, Trevor Darrell, Sergey Levine, Jitendra Malik, <a href="https://people.eecs.berkeley.edu/~pathak/" target="_blank">Deepak Pathak*</a>, <a href="http://www.cs.utexas.edu/~dchen/" target="_blank">Dian Chen*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2018</span> <span class="paper-venue">CVPR</span>
    </div>
    <div class="paper-links"><a href="https://arxiv.org/pdf/1806.08354.pdf" class="paper-link">Paper PDF</a> <a href="data/pathak2018learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A self-supervised method for learning to segment objects by
                interacting with them.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.118.034338" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/circulation18_2.png " alt="Fully Automated Echocardiogram Interpretation in Clinical Practice:
                  Feasibility and Diagnostic Accuracy" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.118.034338" target="_blank">Fully Automated Echocardiogram Interpretation in Clinical Practice:
                  Feasibility and Diagnostic Accuracy</a>
    </h3>
    <div class="paper-authors">Jeffrey Zhang, Sravani Gajjala, Pulkit Agrawal, Geoffrey H Tison, Laura A Hallock, Lauren Beussink-Nelson, Mats H Lassen, Eugene Fan, Mandar A Aras, ChaRandle Jordan, Kirsten E Fleischmann, Michelle Melisko, Atif Qasim, Sanjiv J Shah, Ruzena Bajcsy, Rahul C Deo
               
 Circulation, 2018</div>
    <div class="paper-meta">
      <span class="paper-date">2018</span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.118.034338" class="paper-link">Paper PDF</a> <a href="data/zhang2018fully.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Computer vision method for building fully automated and scalable analysis
                pipeline for echocardiogram interpretation.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="TODO" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/icml17_1.gif" alt="Curiosity Driven Exploration by Self-Supervised Prediction" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="TODO" target="_blank">Curiosity Driven Exploration by Self-Supervised Prediction</a>
    </h3>
    <div class="paper-authors">Deepak Pathak, Pulkit Agrawal, Alexei A. Efros, Trevor Darrell</div>
    <div class="paper-meta">
      <span class="paper-date">2017</span> <span class="paper-venue">ICML</span>
    </div>
    <div class="paper-links"><a href="https://github.com/pathak22/noreward-rl" class="paper-link">Code</a> <a href="data/pathak2017curiosity.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Intrinsic curiosity of agents enables them to learn useful and
                generalizable skills without any rewards from the environment.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Felsen_What_Will_Happen_ICCV_2017_paper.html" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/waterpolo.png" alt="What Will Happen Next?: Forecasting Player Moves in Sports Videos" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Felsen_What_Will_Happen_ICCV_2017_paper.html" target="_blank">What Will Happen Next?: Forecasting Player Moves in Sports Videos</a>
    </h3>
    <div class="paper-authors">Panna Felsen, Pulkit Agrawal, Jitendra Malik 
 
 ICCV, 2017</div>
    <div class="paper-meta">
      <span class="paper-date">2017</span> <span class="paper-venue">ICCV</span>
    </div>
    <div class="paper-links"><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Felsen_What_Will_Happen_ICCV_2017_paper.pdf" class="paper-link">Paper PDF</a> <a href="data/felsen2017iccv.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Feature learning by making use of an agent's knowledge of its motion.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://ropemanipulation.github.io/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/rope-manipulation.png" alt="Combining Self-Supervised Learning and Imitation for Vision-based Rope Manipulation" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://ropemanipulation.github.io/" target="_blank">Combining Self-Supervised Learning and Imitation for Vision-based Rope Manipulation</a>
    </h3>
    <div class="paper-authors">Ashvin Nair, Dian Chen, Pulkit Agrawal, Phillip Isola, Pieter Abbeel, Jitendra Malik, Sergey Levine, <a href="http://ashvin.me/" target="_blank">Ashvin Nair*</a>, <a href="http://www.cs.utexas.edu/~dchen/" target="_blank">Dian Chen*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2017</span> <span class="paper-venue">ICRA</span>
    </div>
    <div class="paper-links"><a href="data/nair2017combining.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Self-supervised learning of low-level skills enables a robot to
                follow a high-level plan specified by a single video demonstration.
                The code for the paperZero Shot Visual Imitationsubsumes this project's code release.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/1611.01843" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/physics_exp.png" alt="Learning to Perform Physics Experiments via Deep Reinforcement Learning" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/1611.01843" target="_blank">Learning to Perform Physics Experiments via Deep Reinforcement Learning</a>
    </h3>
    <div class="paper-authors">Misha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter Battaglia, Nando de Freitas, <a href="https://www.newscientist.com/article/2112455-google-deepminds-ai-learns-to-play-with-physical-objects/" target="_blank">media</a></div>
    <div class="paper-meta">
      <span class="paper-date">2017</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="data/denil2017learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Deep reinforcement learning can equip an agent with the ability
                to perform experiments for inferring physical quanities of interest.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://www.ncbi.nlm.nih.gov/pubmed/29042342" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/safely_cameras.png" alt="Reduction in Fall Rate in Dementia Managed Care through
                 Video Incident Review: Pilot Study" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://www.ncbi.nlm.nih.gov/pubmed/29042342" target="_blank">Reduction in Fall Rate in Dementia Managed Care through
                 Video Incident Review: Pilot Study</a>
    </h3>
    <div class="paper-authors">Eleonore Bayen, Julien Jacquemot, George Netscher, Pulkit Agrawal, Lynn Tabb Noyce, Alexandre Bayen
               
 Journal of Medical Internet Research, 2017</div>
    <div class="paper-meta">
      <span class="paper-date">2017</span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="https://www.jmir.org/2017/10/e339/pdf" class="paper-link">Paper PDF</a> <a href="data/bayen2017reduction.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Analysis how continuous video monitoring and review of falls
                of individuals with dementia can support better quality of care.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/1507.06550" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/ief.gif" alt="Human Pose Estimation with Iterative Error Feedback" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/1507.06550" target="_blank">Human Pose Estimation with Iterative Error Feedback</a>
    </h3>
    <div class="paper-authors">Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, Jitendra Malik</div>
    <div class="paper-meta">
      <span class="paper-date">2016</span> <span class="paper-venue">CVPR</span>
    </div>
    <div class="paper-links"><a href="https://github.com/pulkitag/ief" class="paper-link">Code</a> <a href="data/carreira2016human.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Iterative Error Feedback (IEF) is a self-correcting model that
                progressively changes an initial solution by feeding back error predictions.
                In contrast to feedforward CNNs that only capture structure in inputs,
                IEF captures structure in both the space of inputs and outputs.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://ashvin.me/pokebot-website/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/poking.png" alt="Learning to Poke by Poking: Experiential Learning of Intuitive Physics" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://ashvin.me/pokebot-website/" target="_blank">Learning to Poke by Poking: Experiential Learning of Intuitive Physics</a>
    </h3>
    <div class="paper-authors">Pulkit Agrawal, Ashvin Nair, Pieter Abbeel, Jitendra Malik, Sergey Levine 
 
               
 NIPS, 2016, <a href="http://ashvin.me/" target="_blank">Ashvin Nair*</a></div>
    <div class="paper-meta">
      <span class="paper-date"></span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="data/agrawal2016learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Robot learns how to push objects to target locations by conducting
                a large number of pushing experiments. The code for the paperZero Shot Visual Imitationsubsumes this project's code release.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/1608.08614v2.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/imagenet_thumb.png" alt="What makes Imagenet Good for Transfer Learning?" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/1608.08614v2.pdf" target="_blank">What makes Imagenet Good for Transfer Learning?</a>
    </h3>
    <div class="paper-authors">Jacob Huh, Pulkit Agrawal, Alexei A. Efros 
 
 NIPS LSCVS</div>
    <div class="paper-meta">
      <span class="paper-date"></span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="https://github.com/minyoungg/WMIGFT" class="paper-link">Code</a> <a href="data/huh2016what.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">An empirical investigation into various factors related to the
              statistics of Imagenet dataset that result in transferrable features.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/abs/1511.07404" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/billiards.png" alt="Learning Visual Predictive Models of Physics for Playing Billiards" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/abs/1511.07404" target="_blank">Learning Visual Predictive Models of Physics for Playing Billiards</a>
    </h3>
    <div class="paper-authors">Katerina Fragkiadaki, Pulkit Agrawal, Sergey Levine, Jitendra Malik, <a href="https://www.cs.cmu.edu/~katef/" target="_blank">Katerina Fragkiadaki*</a></div>
    <div class="paper-meta">
      <span class="paper-date">2016</span> <span class="paper-venue">ICLR</span>
    </div>
    <div class="paper-links"><a href="https://github.com/pulkitag/pyphy-engine" class="paper-link">Code</a> <a href="data/fragkiadaki2016learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">This work explores how an agent can be equipped with an internal
                model of the dynamics of the external world, and how it can use this model to plan novel
                actions by running multiple internal simulations (âvisual imaginationâ).</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="http://3drepresentation.stanford.edu/" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/3D_rep.png" alt="Generic 3d Representation via Pose Estimation and Matching" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="http://3drepresentation.stanford.edu/" target="_blank">Generic 3d Representation via Pose Estimation and Matching</a>
    </h3>
    <div class="paper-authors">Amir R. Zamir, Tilman Wekel, Pulkit Agrawal, Colin Weil, Jitendra Malik, Silvio Savarese</div>
    <div class="paper-meta">
      <span class="paper-date">2016</span> <span class="paper-venue">ECCV</span>
    </div>
    <div class="paper-links"><a href="https://github.com/pulkitag/learning-to-see-by-moving" class="paper-link">Code</a> <a href="data/zamir2016generic.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Large-scale study of feature learning using agent's knowledge of its motion.
                This paper extends our ICCV 2015 paper.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Agrawal_Learning_to_See_ICCV_2015_paper.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/lsm_3.png" alt="Learning to See by Moving" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Agrawal_Learning_to_See_ICCV_2015_paper.pdf" target="_blank">Learning to See by Moving</a>
    </h3>
    <div class="paper-authors">Pulkit Agrawal, Joao Carreira, Jitendra Malik 
 
 ICCV, 2015</div>
    <div class="paper-meta">
      <span class="paper-date">2015</span> <span class="paper-venue">ICCV</span>
    </div>
    <div class="paper-links"><a href="https://github.com/pulkitag/learning-to-see-by-moving" class="paper-link">Code</a> <a href="data/agrawal2015learning.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Feature learning by making use of an agent's knowledge of its motion.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/PulkitECCV2014.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/analyzing_2014.png" alt="Analyzing the Performance of Multilayer Neural Networks for Object Recognition" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/PulkitECCV2014.pdf" target="_blank">Analyzing the Performance of Multilayer Neural Networks for Object Recognition</a>
    </h3>
    <div class="paper-authors">Pulkit Agrawal, Ross Girshick, Jitendra Malik</div>
    <div class="paper-meta">
      <span class="paper-date">2014</span> <span class="paper-venue">ECCV</span>
    </div>
    <div class="paper-links"><a href="data/carreira2016human.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">A detailed study of how to finetune neural networks and the
              nature of the learned representations.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://arxiv.org/pdf/1407.5104" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/brain.png" alt="Pixels to Voxels: Modeling Visual Representation in the Human Brain" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://arxiv.org/pdf/1407.5104" target="_blank">Pixels to Voxels: Modeling Visual Representation in the Human Brain</a>
    </h3>
    <div class="paper-authors">Pulkit Agrawal, Dustin Stansbury, Jitendra Malik, Jack Gallant</div>
    <div class="paper-meta">
      <span class="paper-date">2014</span> <span class="paper-venue">arXiv</span>
    </div>
    <div class="paper-links"><a href="data/agrawal2014pixels.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Comparing the representations learnt by a Deep Neural Network
              optimized for object recognition against the human brain.</p>
  </div>
</article>

<article class="paper-card">
  <div class="paper-thumbnail">
    <a href="https://pdfs.semanticscholar.org/0242/a90f7a269ef2d185ca59ada28e4160b638a6.pdf" target="_blank">
      <img src="https://people.csail.mit.edu/pulkitag/images/automatic_assesment.png" alt="The Automatic Assessment of Knowledge Integration Processes in Project Teams" style="border-radius:8px; width:100%; object-fit:cover;">
    </a>
  </div>
  <div class="paper-content">
    <h3 class="paper-title">
      <a href="https://pdfs.semanticscholar.org/0242/a90f7a269ef2d185ca59ada28e4160b638a6.pdf" target="_blank">The Automatic Assessment of Knowledge Integration Processes in Project Teams</a>
    </h3>
    <div class="paper-authors">Gahgene Gweon, Pulkit Agrawal, Mikesh Udani, Bhiksha Raj, Carolyn Rose
               
 Computer Supported Collaborative Learning, 2011
                 (Best Student, <a href="https://pdfs.semanticscholar.org/0242/a90f7a269ef2d185ca59ada28e4160b638a6.pdf" target="_blank">arxiv</a></div>
    <div class="paper-meta">
      <span class="paper-date">2011</span> <span class="paper-venue"></span>
    </div>
    <div class="paper-links"><a href="data/gweon2011automatic.bib" class="paper-link">BibTeX</a></div>
    <p class="paper-abstract">Method for identifying important parts of a group conversation
                directly from speech data.</p>
  </div>
</article>