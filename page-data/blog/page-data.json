{"componentChunkName":"component---src-pages-blog-index-jsx","path":"/blog/","result":{"data":{"allMdx":{"edges":[{"node":{"id":"35fe773a-52b6-58c8-a892-eb0f867778c6","fields":{"slug":"/blog/example_post"},"excerpt":"Hello! Math latex   works. Does this work?","frontmatter":{"date":null,"title":""}}},{"node":{"id":"8c5f6933-2e73-577b-bebb-9bbcd411dda8","fields":{"slug":"/index"},"excerpt":"The Improbable AI Blog Simple Katex   works","frontmatter":{"date":null,"title":""}}},{"node":{"id":"531f89f5-ff11-5cf5-b727-8422c3b106f4","fields":{"slug":"/404"},"excerpt":"Page Not Found Sorry ðŸ˜” we could not find what you were looking for. Try creating a page in  src/pages/.","frontmatter":{"date":null,"title":""}}},{"node":{"id":"eb4da3ac-36fb-5383-88fa-0411f0bc2343","fields":{"slug":"/blog/2022/10-18/relation_rl"},"excerpt":"Solving complex manipulation tasks involving multiple objects is currently impractical for many reinforcement learning (RL) algorithms due to the long time horizon and the increase in state space with the number of objects. These task characteristicsâ€¦","frontmatter":{"date":"October 18, 2022","title":"Relational Reinforcement Learning for Multi-object Manipulation"}}},{"node":{"id":"b4acb465-40a9-5e1c-ad44-e10e0b3e34ff","fields":{"slug":"/blog/2022/10-18/opal"},"excerpt":"Leveraging task-agnostic datasets Several practical concerns may limit the agentâ€™s ability to act directly in the real world. For example, consider the Atlas robot learning via trial and error. This could cause the Atlas to fall frequently requiringâ€¦","frontmatter":{"date":"October 18, 2022","title":"OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning"}}}]}},"pageContext":{}},"staticQueryHashes":[]}